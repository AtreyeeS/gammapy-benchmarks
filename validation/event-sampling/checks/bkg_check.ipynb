{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background checks\n",
    "\n",
    "This nootebook tests the sampling of the background. We simulate only the background and we then fit it, leaving the tilt and normalization parameters free to vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fabio/LAVORO/CTA/GAMMAPY/GIT/gammapy-benchmarks/validation/event-sampling\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "import click\n",
    "import multiprocessing\n",
    "from itertools import repeat\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as u\n",
    "from astropy.convolution import Tophat2DKernel\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from gammapy.cube import (\n",
    "    MapDatasetEventSampler,\n",
    ")\n",
    "from gammapy.data import GTI, Observation, EventList\n",
    "from gammapy.datasets import MapDataset\n",
    "from gammapy.detect import LiMaMapEstimator as lima\n",
    "from gammapy.maps import MapAxis, WcsGeom, Map\n",
    "from gammapy.irf import EnergyDispersion2D, load_cta_irfs\n",
    "from gammapy.makers import MapDatasetMaker\n",
    "from gammapy.maps.profile import ImageProfile, ImageProfileEstimator\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import Models\n",
    "from gammapy.utils.table import table_from_row_data\n",
    "from regions import CircleSkyRegion\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "import gammapy\n",
    "from gammapy.data import EventList\n",
    "from gammapy.maps import MapCoord\n",
    "from gammapy.modeling.models import BackgroundModel, ConstantTemporalModel\n",
    "from gammapy.utils.random import get_random_state\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fabio/LAVORO/CTA/GAMMAPY/GIT/gammapy-benchmarks/validation/event-sampling/checks\n"
     ]
    }
   ],
   "source": [
    "cd checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(filename_dataset):\n",
    "    \"\"\"Prepare dataset for a given skymodel.\"\"\"\n",
    "    log.info(f\"Reading {make.IRF_FILE}\")\n",
    "    irfs = load_cta_irfs(make.IRF_FILE)\n",
    "    observation = Observation.create(\n",
    "        obs_id=1001, pointing=make.POINTING, livetime=make.LIVETIME, irfs=irfs\n",
    "    )\n",
    "\n",
    "    empty = MapDataset.create(make.WCS_GEOM, energy_axis_true=make.ENERGY_AXIS_TRUE, migra_axis=make.MIGRA_AXIS)\n",
    "    maker = MapDatasetMaker(selection=[\"exposure\", \"background\"])\n",
    "    dataset = maker.run(empty, observation)\n",
    "\n",
    "    filename_dataset.parent.mkdir(exist_ok=True, parents=True)\n",
    "    log.info(f\"Writing {filename_dataset}\")\n",
    "    dataset.write(filename_dataset, overwrite=True)\n",
    "\n",
    "\n",
    "def prepare_dataset_fit(filename_dataset):\n",
    "    \"\"\"Prepare dataset for a given skymodel.\"\"\"\n",
    "    log.info(f\"Reading {make.IRF_FILE}\")\n",
    "    irfs = load_cta_irfs(make.IRF_FILE)\n",
    "    observation = Observation.create(\n",
    "        obs_id=1001, pointing=make.POINTING, livetime=make.LIVETIME, irfs=irfs\n",
    "    )\n",
    "\n",
    "    empty = MapDataset.create(WCS_GEOM_fit, energy_axis_true=make.ENERGY_AXIS_TRUE, migra_axis=make.MIGRA_AXIS)\n",
    "    maker = MapDatasetMaker(selection=[\"exposure\", \"background\"])\n",
    "    dataset = maker.run(empty, observation)\n",
    "\n",
    "    filename_dataset.parent.mkdir(exist_ok=True, parents=True)\n",
    "    log.info(f\"Writing {filename_dataset}\")\n",
    "    dataset.write(filename_dataset, overwrite=True)\n",
    "\n",
    "\n",
    "def read_dataset_for_fit(filename_dataset, filename_dataset_fit, filename_model, obs_id):\n",
    "    log.info(f\"Reading {filename_dataset_fit}\")\n",
    "    dataset = MapDataset.read(filename_dataset_fit)\n",
    "\n",
    "    filename_events = make.get_filename_events(filename_dataset, filename_model, obs_id)\n",
    "    log.info(f\"Reading {filename_events}\")\n",
    "    events = EventList.read(filename_events)\n",
    "\n",
    "    counts = Map.from_geom(WCS_GEOM_fit)\n",
    "    counts.fill_events(events)\n",
    "    dataset.counts = counts\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def simulate_events(filename_model, filename_dataset, nobs):\n",
    "    \"\"\"Simulate events of the bkg and dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_model : str\n",
    "        Filename of the model definition.\n",
    "    filename_dataset : str\n",
    "        Filename of the dataset to use for simulation.\n",
    "    nobs : int\n",
    "        Number of obervations to simulate.\n",
    "    \"\"\"\n",
    "    log.info(f\"Reading {make.IRF_FILE}\")\n",
    "    irfs = load_cta_irfs(make.IRF_FILE)\n",
    "\n",
    "    log.info(f\"Reading {filename_dataset}\")\n",
    "    dataset = MapDataset.read(filename_dataset)\n",
    "\n",
    "    sampler = MapDatasetEventSampler(random_state=0)\n",
    "\n",
    "    for obs_id in np.arange(nobs):\n",
    "        observation = Observation.create(\n",
    "            obs_id=obs_id, pointing=make.POINTING, livetime=make.LIVETIME, irfs=irfs\n",
    "        )\n",
    "\n",
    "        events = sampler.run(dataset, observation)\n",
    "\n",
    "        path = make.get_filename_events(filename_dataset, filename_model, obs_id)\n",
    "        log.info(f\"Writing {path}\")\n",
    "        path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        events.table.write(str(path), overwrite=True)\n",
    "        \n",
    "    \n",
    "def fit_model(filename_model, filename_dataset, obs_id, filename_dataset_fit=None):\n",
    "    \"\"\"Fit the events using a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_model : str\n",
    "        Filename of the model definition.\n",
    "    filename_dataset : str\n",
    "        Filename of the dataset to use for simulation.\n",
    "    obs_id : int\n",
    "        Observation ID.\n",
    "    \"\"\"\n",
    "    if filename_dataset_fit is not None:\n",
    "        dataset = read_dataset_for_fit(filename_dataset, filename_dataset_fit, filename_model, obs_id)\n",
    "    else:\n",
    "        dataset = make.read_dataset(filename_dataset, filename_model, obs_id)\n",
    "\n",
    "    dataset.background_model.parameters[\"norm\"].frozen = False\n",
    "    dataset.background_model.parameters[\"tilt\"].frozen = False\n",
    "    \n",
    "    fit = Fit([dataset])\n",
    "\n",
    "#     result = fit.run(optimize_opts={\"print_level\": 1})\n",
    "    result = fit.run()\n",
    "\n",
    "    log.info(f\"Fit info: {result}\")\n",
    "    path = make.get_filename_best_fit_model(filename_model, obs_id, make.LIVETIME)\n",
    "    log.info(f\"Writing {path}\")\n",
    "    dataset.models.write(str(path), overwrite=True)\n",
    "    path = make.get_filename_covariance(path)\n",
    "\n",
    "    log.info(f\"Writing {path}\")\n",
    "\n",
    "    # TODO: exclude background parameters for now, as they are fixed anyway\n",
    "    covariance = result.parameters.get_subcovariance(dataset.models.parameters)\n",
    "    np.savetxt(path, covariance)\n",
    "\n",
    "\n",
    "def fit_gather(model_name, livetime):\n",
    "    rows = []\n",
    "\n",
    "    path = (BASE_PATH / f\"results/models/{model_name}/fit_{livetime.value:.0f}{livetime.unit}\")\n",
    "\n",
    "    for filename in path.glob(\"*.yaml\"):\n",
    "        yaml_str = Path(filename).read_text()\n",
    "        model_best_fit = yaml.safe_load(yaml_str)\n",
    "        path = make.get_filename_covariance(filename)\n",
    "        covariance = np.loadtxt(str(path))\n",
    "\n",
    "        row = {}\n",
    "\n",
    "        for i in np.arange(len(model_best_fit['components'][0]['parameters'])):\n",
    "            name=model_best_fit['components'][0]['parameters'][i]['name']\n",
    "            value=model_best_fit['components'][0]['parameters'][i]['value']\n",
    "            row[name] = value\n",
    "            row[name + \"_err\"] = covariance[i,i]**0.5\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    table = table_from_row_data(rows)\n",
    "    name = f\"fit-results-all_{livetime.value:.0f}{livetime.unit}\"\n",
    "    filename = BASE_PATH / f\"results/models/{model_name}/{name}.fits.gz\"\n",
    "    log.info(f\"Writing {filename}\")\n",
    "    table.write(str(filename), overwrite=True)\n",
    "    \n",
    "\n",
    "def plot_pull_distribution(model_name, livetime):\n",
    "    name = f\"fit-results-all_{livetime.value:.0f}{livetime.unit}\"\n",
    "    filename = BASE_PATH / f\"results/models/{model_name}/{name}.fits.gz\"\n",
    "    results = Table.read(str(filename))\n",
    "\n",
    "    dataset = MapDataset.read(filename_dataset)\n",
    "    dataset.background_model.parameters[\"tilt\"].frozen = False\n",
    "    model_ref = dataset.models\n",
    "    names = [name for name in results.colnames if \"err\" not in name]\n",
    "\n",
    "    plots = f\"plots_{livetime.value:.0f}{livetime.unit}\"\n",
    "    for name in names:\n",
    "        # TODO: report mean and stdev here as well\n",
    "        values = results[name]\n",
    "        values_err = results[name + \"_err\"]\n",
    "        par = model_ref.parameters[name]\n",
    "\n",
    "        if par.frozen:\n",
    "            log.info(f\"Skipping frozen parameter: {name}\")\n",
    "            continue\n",
    "\n",
    "        pull = (values - par.value) / values_err\n",
    "\n",
    "#        print(\"Number of fits beyond 5 sigmas: \",(np.where( (pull<-5) )))\n",
    "        plt.hist(pull, bins=21, density=True, range=(-5,5))\n",
    "        plt.xlim(-5, 5)\n",
    "        plt.xlabel(\"(value - value_true) / error\")\n",
    "        plt.ylabel(\"PDF\")\n",
    "        plt.title(f\"Pull distribution for {model_name}: {name} \")\n",
    "        filename = f\"results/models/{model_name}/{plots}/pull-distribution-{name}.png\"\n",
    "        make.save_figure(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define additional configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "BASE_PATH = Path(\"../make.py\").parent\n",
    "\n",
    "WCS_GEOM_fit = WcsGeom.create(\n",
    "    skydir=make.POINTING, width=(4, 4), binsz=0.1, \n",
    "    frame=\"galactic\", axes=[make.ENERGY_AXIS]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating and fitting the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The truth value of a Quantity is ambiguous. In the future this will raise a ValueError. [astropy.units.quantity]\n"
     ]
    }
   ],
   "source": [
    "change_binning_fit_dataset=True\n",
    "\n",
    "model = 'background'\n",
    "filename_model = BASE_PATH / f\"models/{model}.yaml\"\n",
    "filename_dataset = make.get_filename_dataset(make.LIVETIME)\n",
    "filename_dataset_fit = BASE_PATH / \"data/dataset_1h_fit.fits.gz\"\n",
    "\n",
    "obs_ids=1\n",
    "\n",
    "prepare_dataset(filename_dataset)\n",
    "prepare_dataset_fit(filename_dataset_fit)\n",
    "\n",
    "simulate_events(filename_model=filename_model, filename_dataset=filename_dataset, nobs=obs_ids)\n",
    "obs_ids = f\"0:{obs_ids}\"\n",
    "obs_ids = make.parse_obs_ids(obs_ids, model)\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    if change_binning_fit_dataset==False:\n",
    "        args = zip(repeat(filename_model), repeat(filename_dataset), obs_ids)\n",
    "    else:\n",
    "        args = zip(repeat(filename_model), repeat(filename_dataset), obs_ids, \n",
    "                   repeat(filename_dataset_fit))\n",
    "    results = pool.starmap(fit_model, args)\n",
    "\n",
    "fit_gather(model,make.LIVETIME)\n",
    "plot_pull_distribution(model, make.LIVETIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of the simulated bkg events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'background'\n",
    "obsid=1\n",
    "filename_events = (BASE_PATH / f\"data/models/{model}/events_{make.LIVETIME.value:.0f}{make.LIVETIME.unit}_{obsid:04d}.fits.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = EventList.read(filename_events)\n",
    "\n",
    "evt_pos = SkyCoord(events.table['RA'], events.table['DEC'], frame='icrs')\n",
    "sep = make.POINTING.separation(evt_pos).value\n",
    "\n",
    "hist = plt.hist(sep, bins=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Map.create(frame=\"galactic\", skydir=make.POINTING, width=(4, 4), binsz=0.02)\n",
    "counts.fill_events(events)\n",
    "counts.plot(add_cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ImageProfileEstimator(method='sum', axis='radial', center=make.POINTING)\n",
    "profile = p.run(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = (profile.table['x_max']-profile.table['x_min'])\n",
    "x = profile.table['x_ref']\n",
    "y = profile.table['profile']\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy histogram of the simulated bkg events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = EventList.read(filename_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(events.table['ENERGY'], bins=np.logspace(-1,1,500), \n",
    "                density=True, log=True)\n",
    "# plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
