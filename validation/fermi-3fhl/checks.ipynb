{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from gammapy.data import EventList\n",
    "from gammapy.irf import EnergyDependentTablePSF, EnergyDispersion\n",
    "from gammapy.maps import Map, MapAxis, WcsNDMap, WcsGeom\n",
    "from gammapy.modeling import Fit, Datasets\n",
    "from gammapy.modeling.models import (\n",
    "    SkyDiffuseCube,\n",
    "    SkyModels,\n",
    "    BackgroundModel,\n",
    "    LogParabolaSpectralModel,\n",
    "    PowerLawSpectralModel,\n",
    "    create_fermi_isotropic_diffuse_model,\n",
    ")\n",
    "from gammapy.spectrum import FluxPoints, FluxPointsEstimator\n",
    "from gammapy.cube import MapDataset, PSFKernel, MapEvaluator\n",
    "from gammapy.catalog import SourceCatalog3FHL\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def iscompatible(x, y, dx, dy):\n",
    "    x, y, dx, dy = np.array(x), np.array(y), np.array(dx), np.array(dy)\n",
    "    return abs(y - x) < dx + dy\n",
    "\n",
    "def relative_error(x, y):\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    return (y - x) / x\n",
    "\n",
    "start_time = time()\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "datadir = \"/Users/qremy/Work/Data/gammapy-tutorials/datasets\"  # \"$GAMMAPY_DATA\"\n",
    "resdir = \"/Users/qremy/Work/GitHub/gammapy-fermi-lat-data/3FHL/checks\"  # \"$GAMMAPY_FERMI_LAT_DATA/3FHL/checks/\"\n",
    "\n",
    "events = EventList.read(datadir + \"/fermi_3fhl/fermi_3fhl_events_selected.fits.gz\")\n",
    "exposure_hpx = Map.read(datadir + \"/fermi_3fhl/fermi_3fhl_exposure_cube_hpx.fits.gz\")\n",
    "exposure_hpx.unit = \"cm2 s\"\n",
    "psf = EnergyDependentTablePSF.read(datadir + \"/fermi_3fhl/fermi_3fhl_psf_gc.fits.gz\")\n",
    "iem_fermi = Map.read(datadir + \"/catalogs/fermi/gll_iem_v06.fits.gz\")\n",
    "iem_fermi.unit = \"cm-2 s-1 MeV-1 sr-1\"\n",
    "fileiso = datadir + \"/fermi_3fhl/iso_P8R2_SOURCE_V6_v06.txt\"\n",
    "model_iso = create_fermi_isotropic_diffuse_model(\n",
    "    filename=fileiso, norm=0.92, interp_kwargs={\"fill_value\": None}\n",
    ")  # norm=0.92 see paper appendix A\n",
    "\n",
    "file3fhl = Path(datadir + \"/catalogs/fermi/gll_psch_v13.fit.gz\")\n",
    "FHL3 = SourceCatalog3FHL(file3fhl)\n",
    "hdulist = fits.open(file3fhl)\n",
    "ROIs = hdulist[\"ROIs\"].data\n",
    "nROIs = len(ROIs)\n",
    "Scat = hdulist[1].data\n",
    "order = np.argsort(Scat.Signif_Avg)[::-1]\n",
    "ROIs_ord = Scat.ROI_num[order]\n",
    "nmin = 0  # 10  # 90\n",
    "nmax = 90  # 100  # 250\n",
    "ROIs_sel = np.unique(ROIs_ord[nmin:nmax])\n",
    "# ROIs_sel = [430, 135, 80, 118] #Crab, Vela, GC, high-lat\n",
    "\n",
    "dlb = 0.05\n",
    "El_fit = 10 ** np.arange(1, 3.31, 0.1)\n",
    "El_flux = [10.0, 20.0, 50.0, 150.0, 500.0, 2000.0]  # see hdulist[\"EnergyBounds\"].data\n",
    "energy_axis = MapAxis.from_edges(El_fit, name=\"energy\", unit=\"GeV\", interp=\"log\")\n",
    "psf_r99max = psf.containment_radius(10 * u.GeV, fraction=0.99)\n",
    "psf_margin = np.ceil(psf_r99max.value[0] * 10) / 10.0\n",
    "\n",
    "run_fit = False\n",
    "optimize_opts = {\n",
    "    \"backend\": \"minuit\",\n",
    "    \"migrad_opts\": {\"precision\": 1e-8},\n",
    "}\n",
    "\n",
    "sig_cut = 8.0\n",
    "# calculate flux points only for sources significant above this threshold\n",
    "\n",
    "PL_tags = []\n",
    "PL_index = []\n",
    "PL_amplitude = []\n",
    "PL_BKG_norm = []\n",
    "\n",
    "LP_tags = []\n",
    "LP_amplitude = []\n",
    "LP_alpha = []\n",
    "LP_beta = []\n",
    "LP_BKG_norm = []\n",
    "\n",
    "stat = []\n",
    "message = []\n",
    "compatibility = {}\n",
    "errel = {\"flux_points\": []}\n",
    "cat_fp_sel = []\n",
    "cat_dfp_sel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fit\n",
    "\n",
    "for kr in ROIs_sel:  # nROIs\n",
    "    if run_fit:\n",
    "        roi_time = time()\n",
    "        print(\"ROI \" + str(kr))\n",
    "        ROI_pos = SkyCoord(\n",
    "            ROIs.GLON[kr - 1], ROIs.GLAT[kr - 1], frame=\"galactic\", unit=\"deg\"\n",
    "        )\n",
    "        width = 2 * (ROIs.RADIUS[kr - 1] + psf_margin)\n",
    "        # Counts\n",
    "        counts = Map.create(\n",
    "            skydir=ROI_pos,\n",
    "            width=width,\n",
    "            proj=\"CAR\",\n",
    "            coordsys=\"GAL\",\n",
    "            binsz=dlb,\n",
    "            axes=[energy_axis],\n",
    "            dtype=float,\n",
    "        )\n",
    "        counts.fill_by_coord({\"skycoord\": events.radec, \"energy\": events.energy})\n",
    "        #    counts.sum_over_axes().smooth(2).plot(stretch=\"log\", vmax=50, cmap=\"nipy_spectral\")\n",
    "\n",
    "        axis = MapAxis.from_nodes(\n",
    "            counts.geom.axes[0].center, name=\"energy\", unit=\"GeV\", interp=\"log\"\n",
    "        )\n",
    "        print(counts.geom)\n",
    "        wcs = counts.geom.wcs\n",
    "        geom = WcsGeom(wcs=wcs, npix=counts.geom.npix, axes=[axis])\n",
    "        coords = counts.geom.get_coord()\n",
    "        data = exposure_hpx.interp_by_coord(coords)\n",
    "        exposure = WcsNDMap(geom, data, unit=exposure_hpx.unit, dtype=float)\n",
    "\n",
    "        # read PSF\n",
    "        psf_kernel = PSFKernel.from_table_psf(\n",
    "            psf, counts.geom, max_radius=psf_margin * u.deg\n",
    "        )\n",
    "\n",
    "        # Energy Dispersion\n",
    "        e_true = exposure.geom.axes[0].edges\n",
    "        e_reco = counts.geom.axes[0].edges\n",
    "        edisp = EnergyDispersion.from_diagonal_response(e_true=e_true, e_reco=e_reco)\n",
    "\n",
    "        # fit mask\n",
    "        if coords[\"lon\"].min() < 90 * u.deg and coords[\"lon\"].max() > 270 * u.deg:\n",
    "            coords[\"lon\"][coords[\"lon\"].value > 180] -= 360 * u.deg\n",
    "        mask = (\n",
    "            (coords[\"lon\"] >= coords[\"lon\"].min() + psf_margin * u.deg)\n",
    "            & (coords[\"lon\"] <= coords[\"lon\"].max() - psf_margin * u.deg)\n",
    "            & (coords[\"lat\"] >= coords[\"lat\"].min() + psf_margin * u.deg)\n",
    "            & (coords[\"lat\"] <= coords[\"lat\"].max() - psf_margin * u.deg)\n",
    "        )\n",
    "        mask_fermi = WcsNDMap(counts.geom, mask)\n",
    "        print(\"Maps done\")\n",
    "\n",
    "        # IEM\n",
    "        model_iem = SkyDiffuseCube(iem_fermi, norm=1.1, tilt=0.03, name=\"iem_v06\")\n",
    "        # norm=1.1, tilt=0.03 see paper appendix A\n",
    "        eval_iem = MapEvaluator(\n",
    "            model=model_iem, exposure=exposure, psf=psf_kernel, edisp=edisp\n",
    "        )\n",
    "        bkg_iem = eval_iem.compute_npred()\n",
    "\n",
    "        print(\"Background IEM done\")\n",
    "\n",
    "        # ISO\n",
    "        eval_iso = MapEvaluator(model=model_iso, exposure=exposure, edisp=edisp)\n",
    "        bkg_iso = eval_iso.compute_npred()\n",
    "        print(\"Background ISO done\")\n",
    "\n",
    "        # merge iem and iso, only one local normalization is fitted\n",
    "        background_total = bkg_iem + bkg_iso\n",
    "        background_model = BackgroundModel(background_total)\n",
    "        background_model.parameters[\"norm\"].min = 0.0\n",
    "\n",
    "        # Sources model\n",
    "        in_roi = FHL3.positions.galactic.contained_by(wcs)\n",
    "        FHL3_roi = []\n",
    "        for ks in range(len(FHL3.table)):\n",
    "            if in_roi[ks] == True:\n",
    "                model = FHL3[ks].sky_model()\n",
    "                model.spatial_model.parameters.freeze_all()  # freeze spatial\n",
    "                model.spectral_model.parameters[\"amplitude\"].min = 0.0\n",
    "                if isinstance(model.spectral_model, PowerLawSpectralModel):\n",
    "                    model.spectral_model.parameters[\"index\"].min = 0.1\n",
    "                    model.spectral_model.parameters[\"index\"].max = 10.0\n",
    "\n",
    "                else:\n",
    "                    model.spectral_model.parameters[\"alpha\"].min = 0.1\n",
    "                    model.spectral_model.parameters[\"alpha\"].max = 10.0\n",
    "\n",
    "                FHL3_roi.append(model)\n",
    "        model_total = SkyModels(FHL3_roi)\n",
    "        print(\"Nsources \" + str(len(FHL3_roi)))\n",
    "\n",
    "        # Dataset\n",
    "        dataset = MapDataset(\n",
    "            model=model_total,\n",
    "            counts=counts,\n",
    "            exposure=exposure,\n",
    "            psf=psf_kernel,\n",
    "            edisp=edisp,\n",
    "            background_model=background_model,\n",
    "            mask_fit=mask_fermi,\n",
    "            name=\"3FHL_ROI_num\" + str(kr),\n",
    "        )\n",
    "        cat_stat = dataset.likelihood()\n",
    "\n",
    "        datasets = Datasets([dataset])\n",
    "        results = Fit(datasets).run(optimize_opts=optimize_opts)\n",
    "        fit_stat = datasets.likelihood()\n",
    "        print(results)\n",
    "\n",
    "        if results.message == \"Optimization failed.\":\n",
    "            continue\n",
    "        covariance = results.parameters.covariance\n",
    "        np.save(resdir + \"/3FHL_ROI_num\" + str(kr) + \"_covariance.npy\", covariance)\n",
    "        np.savez(\n",
    "            resdir + \"/3FHL_ROI_num\" + str(kr) + \"_fit_infos.npz\",\n",
    "            message=results.message,\n",
    "            stat=[cat_stat, fit_stat],\n",
    "        )\n",
    "\n",
    "        exec_time = time() - roi_time\n",
    "        print(\"ROI time (s): \", exec_time)\n",
    "\n",
    "        for model in FHL3_roi:\n",
    "            if (\n",
    "                FHL3[model.name].data[\"ROI_num\"] == kr\n",
    "                and FHL3[model.name].data[\"Signif_Avg\"] >= sig_cut\n",
    "            ):\n",
    "                flux_points = FluxPointsEstimator(\n",
    "                    datasets=datasets, e_edges=El_flux, source=model.name, sigma_ul=2.0\n",
    "                ).run()\n",
    "                filename = resdir + \"/\" + model.name + \"_flux_points.fits\"\n",
    "                flux_points.write(filename, overwrite=True)\n",
    "\n",
    "        exec_time = time() - roi_time - exec_time\n",
    "        print(\"Flux points time (s): \", exec_time)\n",
    "        datasets.to_yaml(path=Path(resdir), prefix=dataset.name, overwrite=True)\n",
    "    else:\n",
    "        try:\n",
    "            filedata = Path(resdir + \"/3FHL_ROI_num\" + str(kr) + \"_datasets.yaml\")\n",
    "            filemodel = Path(resdir + \"/3FHL_ROI_num\" + str(kr) + \"_models.yaml\")\n",
    "            dataset = list(Datasets.from_yaml(filedata, filemodel))[0]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        plt.figure(figsize=(6, 6), dpi=150)\n",
    "        ax, cb = dataset.plot_residuals(\n",
    "            method=\"diff/sqrt(model)\",\n",
    "            smooth_kernel=\"gauss\",\n",
    "            smooth_radius=0.1 * u.deg,\n",
    "            region=None,\n",
    "            figsize=(6, 6),\n",
    "            cmap=\"jet\",\n",
    "            vmin=-3,\n",
    "            vmax=3,\n",
    "        )\n",
    "        plt.title(\"Residuals: (Nobs-Npred)/sqrt(Npred)\")\n",
    "        plt.savefig(resdir + \"/resi_\" + dataset.name + \".png\", dpi=150)\n",
    "\n",
    "        plt.figure(figsize=(6, 6), dpi=150)\n",
    "        nobs = dataset.counts.sum_over_axes()\n",
    "        fig, ax, cb = nobs.plot(cmap=cm.nipy_spectral, add_cbar=True, norm=LogNorm())\n",
    "        plt.title(\"Nobs\")\n",
    "        cl = cb.get_clim()\n",
    "        plt.savefig(resdir + \"/counts_\" + dataset.name + \".png\", dpi=plt.gcf().dpi)\n",
    "\n",
    "        plt.figure(figsize=(6, 6), dpi=150)\n",
    "        npred = dataset.npred().sum_over_axes()\n",
    "        fig, ax, cb = npred.plot(cmap=cm.nipy_spectral, add_cbar=True, norm=LogNorm())\n",
    "        plt.title(\"Npred\")\n",
    "        cb.set_clim(cl)\n",
    "        plt.savefig(resdir + \"/npred_\" + dataset.name + \".png\", dpi=plt.gcf().dpi)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    pars = dataset.parameters\n",
    "    pars.covariance = np.load(resdir + \"/\" + dataset.name + \"_covariance.npy\")\n",
    "    infos = np.load(resdir + \"/3FHL_ROI_num\" + str(kr) + \"_fit_infos.npz\")\n",
    "    message.append(infos[\"message\"])\n",
    "    stat.append(infos[\"stat\"])\n",
    "\n",
    "    for model in list(dataset.model):\n",
    "        if (\n",
    "            FHL3[model.name].data[\"ROI_num\"] == kr\n",
    "            and FHL3[model.name].data[\"Signif_Avg\"] >= sig_cut\n",
    "        ):\n",
    "            try:\n",
    "                model.spatial_model.parameters.covariance = pars.get_subcovariance(\n",
    "                    model.spatial_model.parameters\n",
    "                )\n",
    "                model.spectral_model.parameters.covariance = pars.get_subcovariance(\n",
    "                    model.spectral_model.parameters\n",
    "                )\n",
    "                dataset.background_model.parameters.covariance = pars.get_subcovariance(\n",
    "                    dataset.background_model.parameters\n",
    "                )\n",
    "                res_spec = model.spectral_model\n",
    "                cat_spec = FHL3[model.name].spectral_model()\n",
    "\n",
    "                res_fp = FluxPoints.read(\n",
    "                    resdir + \"/\" + model.name + \"_flux_points.fits\"\n",
    "                )\n",
    "                res_fp.table[\"is_ul\"] = res_fp.table[\"ts\"] < 1.0\n",
    "                cat_fp = FHL3[model.name].flux_points.to_sed_type(\"dnde\")\n",
    "                ind = ~(res_fp.is_ul) & ~(cat_fp.is_ul)\n",
    "                errel[\"flux_points\"] += list(\n",
    "                    relative_error(cat_fp.table[\"dnde\"][ind], res_fp.table[\"dnde\"][ind])\n",
    "                )\n",
    "                cat_fp_sel += list(cat_fp.table[\"dnde\"][ind])\n",
    "                cat_dfp_sel += list(\n",
    "                    np.maximum(\n",
    "                        cat_fp.table[\"dnde_errn\"][ind].data,\n",
    "                        cat_fp.table[\"dnde_errp\"][ind].data,\n",
    "                    )\n",
    "                )\n",
    "                energy_range = [0.01, 2] * u.TeV\n",
    "                plt.figure(figsize=(6, 6), dpi=150)\n",
    "                ax = cat_spec.plot(\n",
    "                    energy_range=energy_range,\n",
    "                    energy_power=2,\n",
    "                    label=\"3FHL Catalogue\",\n",
    "                    color=\"k\",\n",
    "                )\n",
    "                cat_spec.plot_error(ax=ax, energy_range=energy_range, energy_power=2)\n",
    "                res_spec.plot(\n",
    "                    ax=ax,\n",
    "                    energy_range=energy_range,\n",
    "                    energy_power=2,\n",
    "                    label=\"Gammapy fit\",\n",
    "                    color=\"b\",\n",
    "                )\n",
    "                res_spec.plot_error(\n",
    "                    ax=ax, energy_range=energy_range, energy_power=2, color=\"c\"\n",
    "                )\n",
    "\n",
    "                cat_fp.plot(ax=ax, energy_power=2, color=\"k\")\n",
    "                res_fp.plot(ax=ax, energy_power=2, color=\"b\")\n",
    "                plt.legend()\n",
    "                tag = model.name\n",
    "                tag.replace(' ', '_')\n",
    "                tag.replace('.', '_')\n",
    "                plt.savefig(\n",
    "                    resdir + \"/spec_\" + tag + \"_ROI_num\" + str(kr) + \".png\",\n",
    "                    dpi=plt.gcf().dpi,\n",
    "                )\n",
    "\n",
    "                if isinstance(model.spectral_model, PowerLawSpectralModel):\n",
    "\n",
    "                    PL_index.append(\n",
    "                        [\n",
    "                            cat_spec.parameters[\"index\"].value,\n",
    "                            res_spec.parameters[\"index\"].value,\n",
    "                            cat_spec.parameters.error(\"index\"),\n",
    "                            res_spec.parameters.error(\"index\"),\n",
    "                        ]\n",
    "                    )\n",
    "                    PL_amplitude.append(\n",
    "                        [\n",
    "                            cat_spec.parameters[\"amplitude\"].value,\n",
    "                            res_spec.parameters[\"amplitude\"].value,\n",
    "                            cat_spec.parameters.error(\"amplitude\"),\n",
    "                            res_spec.parameters.error(\"amplitude\"),\n",
    "                        ]\n",
    "                    )\n",
    "                    PL_BKG_norm.append(\n",
    "                        [\n",
    "                            dataset.background_model.parameters[\"norm\"].value,\n",
    "                            dataset.background_model.parameters.error(\"norm\"),\n",
    "                        ]\n",
    "                    )\n",
    "                    PL_tags.append([dataset.name, model.name])\n",
    "\n",
    "                if isinstance(model.spectral_model, LogParabolaSpectralModel):\n",
    "                    LP_alpha.append(\n",
    "                        [\n",
    "                            cat_spec.parameters[\"alpha\"].value,\n",
    "                            res_spec.parameters[\"alpha\"].value,\n",
    "                            cat_spec.parameters.error(\"alpha\"),\n",
    "                            res_spec.parameters.error(\"alpha\"),\n",
    "                        ]\n",
    "                    )\n",
    "                    LP_beta.append(\n",
    "                        [\n",
    "                            cat_spec.parameters[\"beta\"].value,\n",
    "                            res_spec.parameters[\"beta\"].value,\n",
    "                            cat_spec.parameters.error(\"beta\"),\n",
    "                            res_spec.parameters.error(\"beta\"),\n",
    "                        ]\n",
    "                    )\n",
    "                    LP_amplitude.append(\n",
    "                        [\n",
    "                            cat_spec.parameters[\"amplitude\"].value,\n",
    "                            res_spec.parameters[\"amplitude\"].value,\n",
    "                            cat_spec.parameters.error(\"amplitude\"),\n",
    "                            res_spec.parameters.error(\"amplitude\"),\n",
    "                        ]\n",
    "                    )\n",
    "                    LP_BKG_norm.append(\n",
    "                        [\n",
    "                            dataset.background_model.parameters[\"norm\"].value,\n",
    "                            dataset.background_model.parameters.error(\"norm\"),\n",
    "                        ]\n",
    "                    )\n",
    "                    LP_tags.append([dataset.name, model.name])\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood\n",
    "message = np.array(message)\n",
    "print(\n",
    "    \"Optimization success. : \",\n",
    "    sum(message == \"Optimization terminated successfully.\") / len(message),\n",
    ")\n",
    "print(\"Optimization failed. : \", sum(message == \"Optimization failed.\") / len(message))\n",
    "print(\n",
    "    \"Optimization failed. Estimated distance to minimum too large. : \",\n",
    "    sum(message == \"Optimization failed. Estimated distance to minimum too large.\")\n",
    "    / len(message),\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=120)\n",
    "stat = np.array(stat)\n",
    "plt.plot(stat[:, 0], stat[:, 0] - stat[:, 1], \"+ \")\n",
    "xl = plt.xlim()\n",
    "yl = plt.ylim()\n",
    "plt.ylim([-100, 100])\n",
    "plt.plot(xl, [0, 0], \"-k\")\n",
    "plt.xlabel(\"Cash Catalog\")\n",
    "plt.ylabel(\"dCash Catalog - Fit\")\n",
    "plt.savefig(resdir + \"/Cash_stat_corr\" + \".png\", dpi=plt.gcf().dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flux points\n",
    "name = \"flux_points\"\n",
    "errel[name] = np.array(errel[name])\n",
    "print(\"\\n\" + name)\n",
    "print(\"Rel. err. <10%:\", sum(abs(errel[name]) < 0.1) / len(errel[name]))\n",
    "print(\"Rel. err. <30%:\", sum(abs(errel[name]) < 0.3) / len(errel[name]))\n",
    "print(\"Rel. err. mean:\", np.nanmean(errel[name]))\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=150)\n",
    "plt.semilogx(cat_fp_sel, errel[name], \" .\")\n",
    "xl = plt.xlim()\n",
    "plt.plot(xl, [0, 0], \"-k\")\n",
    "plt.ylim([-1, 1])\n",
    "plt.xlabel(name + \" Catalog\")\n",
    "plt.ylabel(\"Relative error: (Gammapy-Catalog)/Catalog\")\n",
    "if \"amplitude\" in name:\n",
    "    ax = plt.gca()\n",
    "    ax.set_xscale(\"log\")\n",
    "plt.savefig(resdir + \"/\" + name + \"_errel\" + \".png\", dpi=plt.gcf().dpi)\n",
    "\n",
    "\n",
    "# Parameters diagnostics\n",
    "\n",
    "diags = [\n",
    "    np.array(PL_index),\n",
    "    np.array(PL_amplitude),\n",
    "    np.array(LP_alpha),\n",
    "    np.array(LP_beta),\n",
    "    np.array(LP_amplitude),\n",
    "]\n",
    "\n",
    "PL_BKG_norm = np.array(PL_BKG_norm)\n",
    "LP_BKG_norm = np.array(LP_BKG_norm)\n",
    "\n",
    "names = [\"PL_index\", \"PL_amplitude\", \"LP_alpha\", \"LP_beta\", \"LP_amplitude\"]\n",
    "ndiag = len(diags)\n",
    "for kd in range(ndiag):\n",
    "    diag = diags[kd]\n",
    "    name = names[kd]\n",
    "    if len(diag) != 0:\n",
    "        # fit vs. catalogue parameters comparisons\n",
    "        print(\"\\n\" + name)\n",
    "        ind = diag[:, 3] / diag[:, 1] < 0.1\n",
    "        print(\"dx/x <10% : \", sum(ind) / len(diag[:, 1]))\n",
    "        ind = diag[:, 3] / diag[:, 1] < 0.3\n",
    "        print(\"dx/x <30% : \", sum(ind) / len(diag[:, 1]))\n",
    "\n",
    "        plt.figure(figsize=(6, 6), dpi=150)\n",
    "        plt.errorbar(\n",
    "            diag[ind, 0], diag[ind, 1], xerr=diag[ind, 2], yerr=diag[ind, 3], ls=\" \"\n",
    "        )\n",
    "        if \"amplitude\" in name:\n",
    "            ax = plt.gca()\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yscale(\"log\")\n",
    "        xl = plt.xlim()\n",
    "        plt.plot(xl, xl, \"-k\")\n",
    "        plt.xlabel(name + \" Catalog\")\n",
    "        plt.ylabel(name + \" Gammapy\")\n",
    "        plt.savefig(resdir + \"/\" + name + \"_corr\" + \".png\", dpi=plt.gcf().dpi)\n",
    "\n",
    "        # relative error and compatibility\n",
    "        compatibility[name] = iscompatible(\n",
    "            diag[:, 0], diag[:, 1], diag[:, 2], diag[:, 3]\n",
    "        )\n",
    "        errel[name] = relative_error(diag[:, 0], diag[:, 1])\n",
    "\n",
    "        print(\"Rel. err. <10%:\", sum(abs(errel[name]) < 0.1) / len(errel[name]))\n",
    "        print(\"Rel. err. <30%:\", sum(abs(errel[name]) < 0.3) / len(errel[name]))\n",
    "        print(\"Rel. err. mean:\", np.nanmean(errel[name]))\n",
    "        print(\"compatibility:\", sum(compatibility[name]) / len(compatibility[name]))\n",
    "\n",
    "        plt.figure(figsize=(6, 6), dpi=150)\n",
    "        plt.plot(diag[:, 0], errel[name], \" .\")\n",
    "        xl = plt.xlim()\n",
    "        plt.plot(xl, [0, 0], \"-k\")\n",
    "        plt.ylim([-0.3, 0.3])\n",
    "        plt.xlabel(name + \" Catalog\")\n",
    "        plt.ylabel(\"Relative error: (Gammapy-Catalog)/Catalog\")\n",
    "        if \"amplitude\" in name:\n",
    "            ax = plt.gca()\n",
    "            ax.set_xscale(\"log\")\n",
    "        plt.savefig(resdir + \"/\" + name + \"_errel\" + \".png\", dpi=plt.gcf().dpi)\n",
    "\n",
    "        # Background correlation\n",
    "        plt.figure(figsize=(6, 6), dpi=150)\n",
    "        if \"PL\" in name:\n",
    "            bkg_norm = PL_BKG_norm\n",
    "        else:\n",
    "            bkg_norm = LP_BKG_norm\n",
    "        plt.errorbar(\n",
    "            bkg_norm[:, 0], errel[name], xerr=bkg_norm[:, 1], ls=\" \",\n",
    "        )\n",
    "        plt.xlim([0.7, 1.3])\n",
    "        plt.plot([0.7, 1.3], [0, 0], \"-k\")\n",
    "        plt.xlabel(\"BKG norm\")\n",
    "        plt.ylabel(name + \" Relative error\")\n",
    "        plt.savefig(resdir + \"/\" + name + \"_errel_BKGcorr\" + \".png\", dpi=plt.gcf().dpi)\n",
    "\n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time = time() - start_time\n",
    "print(\"\\n Execution time (s): \", exec_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
